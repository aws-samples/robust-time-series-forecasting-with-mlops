{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<sup> Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. </sup>\n",
    "<sup> SPDX-License-Identifier: MIT-0 </sup>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "3c49bac1-6adb-4083-a5e0-17bc647e1392",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Robust Time-Series Forecasting with MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70654de-664b-463c-8c7b-6d2d278f6db9",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The purpose of this notebook is to create a reusable resource that educates users about the Temporal Convolutional Network with Spliced Binned Pareto Distribution and demonstrate various SageMaker MLOps features such as SageMaker Pipelines, Model Registry, and Experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9063c9b-a048-4d50-90e9-91aa1d97cc4b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Jupyter Kernel**:\n",
    "* Please ensure you are using the **Python 3 (Pytorch 1.13 Python 3.9 CPU Optimized)** kernel\n",
    "\n",
    "**Run All**: \n",
    "\n",
    "* If you are in a SageMaker Notebook instance, you can *go to Cell tab -> Run All*\n",
    "* If you are in SageMaker Studio, you can *go to Run tab -> Run All Cells*\n",
    "\n",
    "**Overview**\n",
    "\n",
    "* [Phase I: Model Introduction](#phase_1)\n",
    "* [Phase II: Training Pipeline](#phase_2)\n",
    "* [Phase III: Model Performance Analysis](#phase_3)\n",
    "* [Phase IV: Model Serving](#phase_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d80a10-71bb-4ec6-b3de-9868d568078b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Authors:**\n",
    "* Nick Biso\n",
    "* Alston Chan\n",
    "* Maria Masood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install gluonts==0.11.12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d10647-99bd-42c7-957a-5e36027d8dcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "from io import BytesIO\n",
    "\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.processing import  ProcessingInput, ProcessingOutput\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.pytorch import PyTorch, PyTorchProcessor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.functions import Join, JsonGet\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "from sagemaker.workflow.steps import ProcessingStep, CacheConfig, TuningStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from smexperiments.search_expression import Filter, Operator, SearchExpression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from gluonts.nursery.spliced_binned_pareto.training_functions import highlight_min\n",
    "from processing.generate_data import create_ds_asymmetric\n",
    "from model.utils import plot_sbp_distribution\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524d30b-0d3e-4970-afa8-f6297e08d6fa",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.Session().region_name\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.resource('s3')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "s3_resource = boto3.resource('s3', region_name=region)\n",
    "s3_bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "print(f\"account_id: {account_id}\")\n",
    "print(f\"region: {region}\")\n",
    "print(f\"bucket_name: {bucket_name}\")\n",
    "print(f\"role: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f205d54-b417-4d7e-b6f2-b75bf5a53083",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='phase_1'></a>\n",
    "## Phase I: Model Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5d049-6f8a-41b0-b7cf-4dead21a5862",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For this exercise, we utilize a [DistributionalTCN with Spliced Binned-Pareto distribution](https://www.amazon.science/publications/spliced-binned-pareto-distribution-for-robust-modeling-of-heavy-tailed-time-series). This model is specifically designed for time-series forecasting and offers robustness against extreme observations in addition to capturing the main distribution.\n",
    "\n",
    "The architecture of the model consists of convolutional layers responsible for extracting temporal features. These are followed by fully connected layer(s) and finally a distributional layer which represents the probability distribution of the predictions. We then fit the Spliced Binned-Pareto distribution into the aforementioned distributional layer, which utilizes a flexible binned distribution to model the base and two Generalized Pareto Distributions to capture the tails. Displayed below is a table that illustrates the flexibility of the distribution compared to predecessor methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00629264-6068-4b90-996b-604cfeb4eaba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<center>  <img src=\"images/comparison.png\" alt=\"comparison\" width=\"700\"/> </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db053e22-3551-4b9b-8d4b-99c02f8bbd18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A multivariate time-series concatenated with static features version of this solution has been applied to model [NFL's Next Gen stat's new Passing Metric](https://www.amazon.science/blog/the-science-behind-nfl-next-gen-stats-new-passing-metric). Model performance can be found in the link provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5dccaa-4557-4267-8e18-0d83afb18552",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='phase_2'></a>\n",
    "## Phase II: Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba0be1-19e0-426f-a95b-a8b877f665dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section, we will guide you through the training pipeline employing SageMaker Pipelines, which is composed of the following steps:\n",
    "* [Data Generation](#data_generation)\n",
    "* [Hyperparameter Tuning Step](#hyperparameter_tuning)\n",
    "* [Model Step](#model_step)\n",
    "* [Model Evaluation Step](#model_evaluation)\n",
    "* [Model Registration](#model_registration)\n",
    "* [Condition Step](#condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<center>  <img src=\"images/pipeline.png\" alt=\"pipeline\" width=\"75%\" height=\"75%\"/> </center>  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Variables and helper function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "project_name = \"SBP\"\n",
    "pipeline_name = project_name + \"-Pipeline\"\n",
    "experiment_name = pipeline_name + \"-Experiment\"\n",
    "model_package_group_name = project_name + \"-ModelGroup\"\n",
    "\n",
    "# Return an S3 path based on the id of this pipeline execution, which is a property only\n",
    "# resolved at runtime but can be accessed at compile time as an execution variable\n",
    "def dynamic_S3_path(path):\n",
    "    return Join(\n",
    "        on=\"/\",\n",
    "            values=[\n",
    "                \"s3:/\",\n",
    "                bucket_name,\n",
    "                pipeline_name,\n",
    "                \"executions\",\n",
    "                ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                path,\n",
    "            ],\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Sagemaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This powerful tool allows the creation of ML workflows seamlessly integrated with sagemaker features, using  a user-friendly Python SDK. These workflows can be easily visualized and managed in SageMaker Studio under `Home → Pipelines` on the left tab.\n",
    "\n",
    "When using Sagemaker Pipelines, you can store and reuse workflow steps leading to increased efficiency and scalability. Furthermore, built-in templates facilitate the swift building, experimenting, evaluating, and registration of models expediting the implementation of CI/CD in your ML environment.\n",
    "\n",
    "SageMaker Pipelines create a Directed Acyclic Graph (DAG) where each node is referred to as a `Step` which have a variety of [types](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-steps-types) and whose Edges are its requisites that can either be defined using [data dependency](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-properties) or a [custom type dependency](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-custom-dependency)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define Variables**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pipeline Session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_session = PipelineSession()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Cache Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html) \\\n",
    "To optimize cost and time, we utilize step caching in the pipeline. By caching the steps, we avoid re-executing them if their outputs remain the same. This means that if a step has already been successfully executed with the same input data and parameters, the cached result will be used instead of recomputing the step."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after=\"7d\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Define Sagemaker Pipelines parameters** \\\n",
    "Below variables are the default values used in our pipeline. It can be overwritten in [this cell](#overwrite_variables) of the notebook and when executing using the UI. This can also be done by going on the left pane and then clicking: `Home → Pipelines → Pipeline Name → Create Execution`. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_parameters = {}\n",
    "\n",
    "pipeline_parameters['train_data_size'] = ParameterInteger(\n",
    "    name=\"TrainDataSize\",\n",
    "    default_value=5_000,\n",
    ")\n",
    "\n",
    "pipeline_parameters['val_data_size'] = ParameterInteger(\n",
    "    name=\"ValidationDataSize\",\n",
    "    default_value=1_000,\n",
    ")\n",
    "\n",
    "pipeline_parameters['test_data_size'] = ParameterInteger(\n",
    "    name=\"TestDataSize\",\n",
    "    default_value=1_000,\n",
    ")\n",
    "\n",
    "pipeline_parameters['model_approval_status'] = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", \n",
    "    default_value=\"Approved\"\n",
    ")\n",
    "\n",
    "pipeline_parameters['context_length'] = ParameterString(\n",
    "    name=\"ContextLength\", \n",
    "    default_value=\"100\"\n",
    ")\n",
    "\n",
    "pipeline_parameters['lead_time'] = ParameterString(\n",
    "    name=\"LeadTime\", \n",
    "    default_value=\"1\"\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will set the default training instance type as `ml.g4dn.xlarge` which is a GPU instance. The comprehensive list of instance types can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html). To save on cost, we will be [overwriting this instance with CPUs](#overwrite_variables). Furthermore, the use of multiple GPUs will require a [service quota increase request](https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html). It may take time and further communication to get approval depending on type of instance. The reason you may want to consider use of GPUs is because they may lower compute time for training neural networks especially for larger batch sizes. It is recommended to analyze compute time and cost whenever you are performing rigorous hyperparameter tuning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Table of Price Comparison (us-east-1)\n",
    "Below is the estimated cost per training job of an SBP model. When changing training instance type, ensure that you also change the instance type of the [training image](#image). For our use-case, due to the very small dataset we are using coupled with the simple architecture, we are not noticing any major differences in training time. Pricing is dependent on the [region](https://aws.amazon.com/sagemaker/pricing/)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Instance Type                     | Price per Hour | Compute Time |     Total Cost |\n",
    "|:----------------------------------|---------------:|-------------:|---------------:|\n",
    "| ml.m5.xlarge (Standard Instance)  |  &dollar;0.204 |      ~8 Mins | &dollar; 0.027 |\n",
    "| ml.m5.2xlarge (Standard Instance) |   &dollar;0.23 |      ~7 Mins | &dollar; 0.027 |\n",
    "| ml.c5.xlarge (Compute-Optimized)  |  &dollar;0.204 |      ~7 Mins | &dollar; 0.024 |\n",
    "| ml.c5.2xlarge (Compute-Optimized) |  &dollar;0.408 |      ~5 Mins | &dollar; 0.034 |\n",
    "| ml.g4dn.xlarge (GPU)              | &dollar;0.7364 |      ~8 Mins | &dollar; 0.098 |\n",
    "| ml.g4dn.2xlarge (GPU)             |   &dollar;0.94 |      ~7 Mins | &dollar; 0.110 |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_parameters['training_instance_type'] = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.g4dn.xlarge\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of the below training parameters are within the default ranges of SageMaker [Service Quotas](https://us-west-1.console.aws.amazon.com/servicequotas/home/services/sagemaker/quotas). If needed, feel free to [request an increase](https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html) for any of the following:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_parameters['max_jobs'] = ParameterInteger(\n",
    "    name=\"MaxJobs\", \n",
    "    default_value=2\n",
    ")\n",
    "\n",
    "pipeline_parameters['max_parallel_jobs'] = ParameterInteger(\n",
    "    name=\"MaxParallelJobs\", \n",
    "    default_value=2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_parameter_list = list(pipeline_parameters.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='image'></a>\n",
    "**Define Images** \\\n",
    "We will be using Deep Learning Containers (DLC's) to run the majority of the Pipeline Steps. Full list of images can be found in this [link](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_image_uri = image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    version='1.13',\n",
    "    py_version='py39',\n",
    "    image_scope='training', \n",
    "    instance_type='ml.c5.2xlarge'\n",
    ")\n",
    "\n",
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    version='1.13',\n",
    "    py_version='py39',\n",
    "    image_scope='inference', \n",
    "    instance_type=\"ml.c5.2xlarge\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='data_generation'></a>\n",
    "#### Data Generation Step\n",
    "We will be leveraging a synthetic time series dataset that exhibits a sinusoidal mean and asymmetric heavy-tailed noise. This data will be generated during the execution of SageMaker Pipelines.\n",
    "\n",
    "To generate the data, we will utilize the `create_ds_asymmetric` function from the `processing.generate_data` module. Below is a sample of the data generated using this function. You can access the actual data generated by your pipeline in the `plots` directory of the execution folder associated with this notebook. Please ensure that you have run all the necessary steps leading up to this point for the link in the [cell](#s3_path) to work and generate the data.\n",
    "\n",
    "To perform these calculations we are using a [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<center>  <img src=\"images/train_data.png\" alt=\"train_data\"/> </center> "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_job_name = f\"{pipeline_name}/data-generation-step\"\n",
    "\n",
    "script_processor = PyTorchProcessor( \n",
    "    command=['python3'],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    base_job_name=base_job_name,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    framework_version='1.13',\n",
    "    py_version='py39'\n",
    ")\n",
    "\n",
    "\n",
    "processor_run_args = script_processor.run(\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=dynamic_S3_path(\"train\")\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=dynamic_S3_path(\"validation\")\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=dynamic_S3_path(\"test\")\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"plots\",\n",
    "            source=\"/opt/ml/processing/plots\",\n",
    "            destination=dynamic_S3_path(\"plots\")\n",
    "        ),\n",
    "    ],\n",
    "    code=\"processing/generate_data.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"GenerateData\",\n",
    "    step_args=processor_run_args,\n",
    "    job_arguments=[\n",
    "        \"--train_size\",\n",
    "        str(pipeline_parameters['train_data_size'].default_value),\n",
    "        \"--validation_size\",\n",
    "        str(pipeline_parameters['val_data_size'].default_value),\n",
    "        \"--test_size\",\n",
    "        str(pipeline_parameters['test_data_size'].default_value),\n",
    "    ],\n",
    "    cache_config=cache_config\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='hyperparameter_tuning'></a>\n",
    "#### [Hyperparameter Tuning Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sagemaker provides a [hyperparameter tuning](https://aws.amazon.com/sagemaker/automatic-model-tuning/) feature that is also available within SageMaker Pipelines. This step runs multiple jobs optionally in parallel, in a [variety of methods](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) using predefined [Hyperparameter ranges](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html). During training, this feature conveniently tracks [model metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics-variables.html) by parsing **stdout** and **strerr**. This step returns the best model based on the aforementioned model metrics.\n",
    "\n",
    "To optimize costs, we will focus our tuning efforts on a select subset of the available hyperparameters, specifically those that effectively showcase SageMaker's Hyperparameter Tuning feature. There are three types of hyperparameters at our disposal for this purpose: \n",
    " * **Time-series Related:** due to the synthetic nature of our data, this set of parameters will be irrelevant, so we will be keeping it static.\n",
    "     * `Context Length` - Number of recent historical time steps that will be fed into the model\n",
    "     * `Lead Time` - Number of time steps to predict AKA forecast horizon \n",
    " * **Neural Network Related:** we will be tuning our model to the hyperparameters below. \n",
    "     * `Learning Rate` - Yes\n",
    "     * `Epochs` - Yes\n",
    "     * `Number of TCN Layers` - No \n",
    " * **Spliced Binned Pareto [Specific Parameters](model/sbp.py):**\n",
    "     * `Number of Bins`  (100) - This number is used to create the number of bins used to model the base of the distribution. The authors of the model have tested this parameter across different datasets in many different industries, and this number has shown to be most effective.\n",
    "     * `Percentile Tail`  (0.05) - This parameter represents the size of the generalized Pareto distributions at the tail. Similar to the previous parameter, it has been rigorously tested by the authors.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distributions = [\"sbp\", \"gaussian\"] \n",
    "\n",
    "def create_model_component(model_name):\n",
    "    estimator = PyTorch(\n",
    "        role=role,\n",
    "        instance_type=pipeline_parameters['training_instance_type'],\n",
    "        output_path=f\"s3://{bucket_name}/{pipeline_name}/models/\",\n",
    "        instance_count=1,\n",
    "        source_dir='model',\n",
    "        image_uri=train_image_uri,\n",
    "        entry_point=model_name + \".py\",\n",
    "        base_job_name = f\"{pipeline_name}/training/job\",\n",
    "    )\n",
    "\n",
    "    hyper_ranges = {\n",
    "        \"learning-rate\": ContinuousParameter(1e-5, 1e-4,  scaling_type=\"Logarithmic\"),\n",
    "        \"epochs\": IntegerParameter(30, 40),\n",
    "    }\n",
    "\n",
    "    objective_name = \"logloss\"\n",
    "    metric_definitions = [{\"Name\": objective_name, \"Regex\": \"Validation Loss: ([0-9\\\\.]+)\"}]\n",
    "\n",
    "    tuner_log = HyperparameterTuner(\n",
    "        estimator,\n",
    "        objective_name,\n",
    "        hyper_ranges,\n",
    "        metric_definitions,\n",
    "        max_jobs=pipeline_parameters['max_jobs'], \n",
    "        max_parallel_jobs=pipeline_parameters['max_parallel_jobs'],\n",
    "        objective_type=\"Minimize\",\n",
    "        base_tuning_job_name=f\"{pipeline_name}/HPTuning/{model_name}\",\n",
    "        random_seed=10\n",
    "    )\n",
    "\n",
    "    step_tuning = TuningStep(\n",
    "        name=f\"{model_name}-HpTuning\",\n",
    "        display_name=f\"{model_name}-HpTuning\",\n",
    "        tuner=tuner_log,\n",
    "        inputs={\n",
    "            'train': TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "           \"validation\": TrainingInput(\n",
    "                s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "        job_arguments=[\n",
    "            \"--lead_time\",\n",
    "            str(pipeline_parameters['lead_time'].default_value),\n",
    "            \"--context_length\",\n",
    "            str(pipeline_parameters['context_length'].default_value),\n",
    "        ],\n",
    "        cache_config=cache_config\n",
    "    )\n",
    "    \n",
    "    return step_tuning\n",
    "    \n",
    "tuning_steps = [create_model_component(distribution) for distribution in distributions]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='model_step'></a>\n",
    "#### [Model Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upon finishing the hyperparameter tuning process, we will create a [SageMaker Model Object](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html) from the outputs of the best tuning job. This SageMaker Model object will be used in the [endpoint step](#endpoint_step) to deploy the trained model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model_step(tuning_step):\n",
    "    model_name = tuning_step.display_name.split('-')[0]\n",
    "    best_model = PyTorchModel(\n",
    "        source_dir='model',\n",
    "        entry_point=model_name + \".py\",\n",
    "        role=role,\n",
    "        model_data=tuning_step.get_top_model_s3_uri(\n",
    "            top_k=0, \n",
    "            s3_bucket=bucket_name, \n",
    "            prefix=f\"{pipeline_name}/models\"\n",
    "        ),\n",
    "        image_uri=inference_image_uri,\n",
    "        sagemaker_session=pipeline_session,\n",
    "    )\n",
    "\n",
    "    model_step = ModelStep(\n",
    "        name=f'{model_name}-CreateModel',\n",
    "        display_name=f'{model_name}-CreateModel',\n",
    "        step_args=best_model.create(instance_type=\"ml.c5.2xlarge\"),\n",
    "    )\n",
    "    return best_model, model_step, model_name\n",
    "\n",
    "best_models = {}\n",
    "model_steps = []\n",
    "for tuning_step in tuning_steps:\n",
    "    best_model, model_step, model_name = create_model_step(tuning_step)\n",
    "    best_models[model_name] = best_model\n",
    "    model_steps.append(model_step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='model_evaluation'></a>\n",
    "#### Model Evaluation Step\n",
    "To perform these calculations we are using a [Pytorch Processor](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job-frameworks-pytorch.html), which is a type of  [Processing Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing) in SageMaker Pipelines. This step measures the performance of our trained model using the test set, which was not used during the hyperparameter tuning stage. The test set contains data that has never been seen before, making it a good representation of the model's accuracy in real-world scenarios.\n",
    "\n",
    "To evaluate the accuracy of the density estimation of each of the method, we use Probability-Probability (PP) plots (PP-plots). For a given quantile level $q$, we compute $ y_q$, which is the fraction of points that fell below the given quantile $z_q{(t)} $ of their corresponding predictive distribution:\n",
    "\\begin{align}\n",
    "  y_q = \\frac{\\sum_{t=2}^{T} \\mathbb{I}[ {x}_t < z_{1-q}{(t)} ] }{T}, \\hspace{40pt}   z_q{(t)} : p\\left( {x}_{t} > z_q{(t)} \\middle| {x}_{1:t-1} \\right)< q\n",
    "\\end{align}\n",
    "To obtain a quantitative score, we measure how good the tail estimate is by computing the Root Mean Square Error (RMSE) between  $y_q $ and $q $ for all measured quantiles $q$.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "script_eval = PyTorchProcessor(\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name = f\"{pipeline_name}/evaluation/job\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    "    framework_version='1.13',\n",
    "    py_version='py39',\n",
    ")\n",
    "\n",
    "\n",
    "eval_inputs = [\n",
    "    ProcessingInput(\n",
    "        source=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/input/train\",\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/input/validation\",\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/input/test\",\n",
    "    )\n",
    "]\n",
    "\n",
    "for tuning_step in tuning_steps:\n",
    "    eval_inputs.append(\n",
    "        ProcessingInput(\n",
    "            source=tuning_step.get_top_model_s3_uri(\n",
    "                top_k=0, \n",
    "                s3_bucket=bucket_name, \n",
    "                prefix=f\"{pipeline_name}/models\"\n",
    "            ),\n",
    "            destination=f\"/opt/ml/processing/model/{tuning_step.display_name.split('-')[0]}\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "processor_args = script_eval.run(\n",
    "    code=\"processing/evaluate.py\",\n",
    "    inputs=eval_inputs,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\", \n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=dynamic_S3_path(\"evaluation\")\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"plots\",\n",
    "            source=\"/opt/ml/processing/plots\",\n",
    "            destination=dynamic_S3_path(\"plots\")\n",
    "        ),\n",
    "    ],\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Property Files](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After performing the evaluation and generating the desired metrics and results in the PyTorch Processor step, we store the outputs in a property file. This property file serves as a record of the evaluation and contains important information such as the model's performance metrics, accuracy measures, and any other relevant evaluation results.\n",
    "\n",
    "Storing the outputs in a property file allows for easy access and retrieval of the evaluation results. It provides a structured format to organize and store the information generated during the evaluation process. This file can be used for further analysis, reporting, or tracking the performance of different models over time.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"BestTuningModelEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateTopModel\",\n",
    "    step_args=processor_args,\n",
    "    property_files=[evaluation_report],\n",
    "   cache_config=cache_config\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"],\n",
    "            'evaluation.json'\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)\n",
    "In this step we are preparing the Sagemaker Model Object for deployment. The register method, specific to SageMaker, generates a model package encompassing essential parameters such as content types and AWS instances for inference and transformation. Each model is then wrapped in a `ModelStep`, essentially a package of the model with its associated metadata, ready for deployment.\n",
    "\n",
    "By leveraging SageMaker Model Registry, we can catalog models primed for production and also manage model versions, associate important metadata, and control the approval status of a model. The registry also facilitates model deployment to production and sets the stage for continuous integration and continuous deployment (CI/CD) pipelines, ensuring seamless model deployment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='model_registration'></a>\n",
    "#### Model Registration Step "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "registration_steps = {}\n",
    "for model_name in best_models.keys():\n",
    "    register_args = best_models[model_name].register(\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.c5.2xlarge\"],\n",
    "        transform_instances=[\"ml.c5.2xlarge\"],\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=pipeline_parameters['model_approval_status'],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        description=\"Robust Deep Time-Series Forecasting\",\n",
    "        task=\"REGRESSION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        image_uri=inference_image_uri\n",
    "    )\n",
    "    registration_steps[model_name] = ModelStep(\n",
    "        name=model_name, \n",
    "        step_args=register_args\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='condition'></a>\n",
    "#### [Condition Step ](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we have evaluated the models with the best set of hyperparameters, we will now need to choose one model type (either SBP or Gaussian) to upload to our model registry. We make this selection based on the technique that performed better in overall full distribution accuracy.\n",
    "\n",
    "SageMaker Pipelines has a condition step that enables us to do this by inputting the evaluation_report (`PropertyFile`) of both models and comparing them. For our purposes, we will be selecting the model type that has the lower RMSE, deeming it the \"best\" and will move on to the next step.\n",
    "\n",
    "By leveraging the condition step in SageMaker Pipelines, we can automate this decision-making process and seamlessly move forward with the selected model type for further steps in the pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "condition_steps = []\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"sbp.full_distribution\"\n",
    "    ),\n",
    "    right=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"gaussian.full_distribution\"\n",
    "    )\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"SbpLowerRmse\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[registration_steps['sbp']],\n",
    "    else_steps=[registration_steps['gaussian']],\n",
    ")\n",
    "\n",
    "condition_steps.append(step_cond)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='create_pipeline'></a>\n",
    "#### Create Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`PipelineExperimentConfig` links an experiment to a specific Pipeline execution using a unique run group identifier, such as `SbpForecastTrialExperiment-SBP-Pipeline`. This identifier groups together runs that are associated with the same execution, simplifying the tracking and management of experiments.\n",
    "\n",
    "This feature enables us to track and compare the performance and outcomes of different runs, allowing for effective experimentation and iteration in machine learning workflows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "steps = [step_process] + tuning_steps + [step_eval] + condition_steps \n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=pipeline_parameter_list,\n",
    "    steps=steps,\n",
    "    pipeline_experiment_config=PipelineExperimentConfig(\n",
    "        experiment_name,\n",
    "        Join(\n",
    "            on=\"-\", \n",
    "            values=[\n",
    "                \"SbpForecastTrialExperiment\", \n",
    "                pipeline_name\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "pipeline.upsert(role_arn=role)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='overwrite_variables'></a>\n",
    "<b>Overwrite default variables</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        TrainingInstanceType=\"ml.c5.2xlarge\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='s3_path'></a>\n",
    "<b>Execution Details:</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "execution_id = execution.describe()['PipelineExecutionArn'].split('/')[-1]\n",
    "print(f\"Pipeline Execution ID: {execution_id}\")\n",
    "print(f\"Execution Artifacts Link: https://s3.console.aws.amazon.com/s3/buckets/sagemaker-{region}-{account_id}?prefix={pipeline_name}/executions/{execution_id}/&region={region}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "execution.wait()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "execution.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='phase_3'></a>\n",
    "## Phase III: Model Performance Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is the table used by the [condition step](#condition) to select the better model between the TCN with Gaussian distribution and TCN with SBP distribution. The Spliced Binned Pareto Distribution produced a lower RMSE on all segments based on its best model against the Gaussian Distribution's model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "content_object = s3_resource.Object(bucket_name, f\"{pipeline_name}/executions/{execution_id}/evaluation/evaluation.json\")\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "rmse_table = pd.DataFrame(json_content).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\n",
    "    rmse_table.style.set_caption(\"Root Mean Square Error (RMSE)\")\n",
    "    .set_table_styles(\n",
    "        [{\"selector\": \"caption\", \"props\": [(\"font-size\", \"16px\")]}]\n",
    "    )\n",
    "    .apply(highlight_min)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PP-Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Probability-Probability Plot assesses the goodness of fit between two distributions (actual vs predicted). A perfect fit would entail all points to be on the diagonal, and the further away it is, the less it is conforming to the actual distribution. In the below plots, we are comparing the SBP vs Gaussian's predicted distribution against the actual distribution. As we can observe, SBP's predicted distribution is closer to the actual distribution compared to Gaussian's predicted distribution.\n",
    "\n",
    "The below plot was created in the [Model Evaluation step](#model_evaluation)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_from_s3(img_name, bucket=s3_bucket):\n",
    "    image_object = bucket.Object(f'{pipeline_name}/executions/{execution_id}/plots/{img_name}')\n",
    "    image = mpimg.imread(BytesIO(image_object.get()['Body'].read()), 'png')\n",
    "\n",
    "    plt.figure(figsize=(36, 8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_from_s3(\"evaluation_plot.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Experiments](https://aws.amazon.com/sagemaker/experiments/)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SageMaker Experiments is a managed service for creating, managing, and analyzing ML experiments at scale. Experiments are defined as a collection of runs, which consist of all the inputs, parameters, configurations, and results for one interaction of model training. \n",
    "\n",
    "SageMaker Experiments is [integrated with hyperparameter optimization (HPO) jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-sm-integrations.html), so the [hyperparameter tuning step](#hyperparameter_tuning) automatically creates HPO experiments and runs for each training job completed. \n",
    "\n",
    "SageMaker Experiments is also [integrated with Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-experiments.html), so the [pipeline creation step](#create_pipeline) automatically creates Pipeline experiments and runs if they do not already exist. This step sets the experiment name to `SBP-Pipeline-experiment` and defines a run group identifier `SbpForecastTrialExperiment-SBP-Pipeline` to group runs associated with the same pipeline execution. \n",
    "\n",
    "You can view and analyze these experiments and runs by using SageMaker Studio's [experiment browser](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-view-compare.html).\n",
    "\n",
    "For further exploration of the hyperparameter tuning results, you can leverage the [capability to search for training job runs using the current execution id](https://github.com/aws-samples/sagemaker-experiments-and-pipelines/blob/main/02-PipelineExperiments.ipynb). The code below provides an approach to delve into the details and insights gained from the hyperparameter tuning process."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SM Pipeline injects the Execution ID into the display name\n",
    "source_arn_filter = Filter(\n",
    "    name=\"DisplayName\", \n",
    "    operator=Operator.CONTAINS, \n",
    "    value=execution_id\n",
    ")\n",
    "\n",
    "source_type_filter = Filter(\n",
    "    name=\"Source.SourceType\", \n",
    "    operator=Operator.EQUALS, \n",
    "    value=\"SageMakerTrainingJob\"\n",
    ")\n",
    "\n",
    "search_expression = SearchExpression(\n",
    "    filters=[source_arn_filter, source_type_filter]\n",
    ")\n",
    "\n",
    "component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    search_expression=search_expression.to_boto()\n",
    ")\n",
    "analytic_table = component_analytics.dataframe()\n",
    "analytic_table = analytic_table[~analytic_table['sagemaker_estimator_module'].isnull()] # Remove repack model training job (model/_repack_model.py)\n",
    "analytic_table.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Best Model From Model Registry"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_package_dict = sm_client.list_model_packages(\n",
    "        ModelPackageGroupName=model_package_group_name,\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        MaxResults=100,\n",
    "    )[\"ModelPackageSummaryList\"][0]\n",
    "\n",
    "model_description = sm_client.describe_model_package(\n",
    "    ModelPackageName=model_package_dict[\"ModelPackageArn\"]\n",
    ")\n",
    "\n",
    "model_package_arn = model_description[\"ModelPackageArn\"]\n",
    "model = ModelPackage(\n",
    "    role=role, \n",
    "    model_package_arn=model_package_arn, \n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='phase_4'></a>\n",
    "## Phase IV: Model Serving"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In terms of scoring the model (applying the model to a new dataset), you have two options:\n",
    "1. Using [Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) as part of the same pipeline or the use of a separate [Inference Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-batch.html). A scenario of when you might want to consider using these pipelines is if you don't require live predictions and can tolerate some buffer when processing because this methodology will save you on cost. This technique is optimal for forecasting larger time steps like daily, weekly or monthly intervals.\n",
    "2. Creating a [Real-Time Inference Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html) or a [Serverless Inference Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html). This is perfect for cases when you need to perform time-sensitive predictions at the expense of higher financial cost. Currently, SageMaker Pipelines does not support the inclusion of deploying and scoring an endpoint within a pipeline.\n",
    "\n",
    "The choice between Batch Transform and a real-time inference endpoint depends on your specific requirements. Consider your application's needs, including the requirement for real-time predictions and the associated cost considerations, when deciding which approach to take for scoring your model within the SageMaker pipeline.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='endpoint_step'></a>\n",
    "### [Deploy Endpoint](https://aws.amazon.com/sagemaker/deploy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example pipeline, we deploy a real-time inference endpoint. You can view this endpoint in Sagemaker Studio under `Home -> Deployments -> Endpoints`.\n",
    "\n",
    "Our PyTorch model [serves requests](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#serve-a-pytorch-model) according to [model/endpoint_serving.py](model/endpoint_serving.py).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "endpoint_name = \"SBP-endpoint-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(f\"EndpointName: {endpoint_name}\")\n",
    "model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor = Predictor(endpoint_name=endpoint_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Score the model with completely new data. This is an example of how the model functions within a production environment, generating predictions for datasets that have not been encountered previously."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(275)\n",
    "new_data = create_ds_asymmetric(300)\n",
    "payload = {\"inputs\": [[new_data.tolist()[0][0][-103:]]]}\n",
    "jstr = json.dumps(payload)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = predictor.predict(\n",
    "    jstr,\n",
    "    initial_args={\n",
    "        \"ContentType\": 'application/json'\n",
    "    }\n",
    ")\n",
    "prediction = ast.literal_eval(p.decode(\"utf-8\"))\n",
    "prediction_df = pd.DataFrame(prediction)\n",
    "historical_list = new_data.tolist()[0][0]\n",
    "\n",
    "plot_sbp_distribution(\n",
    "    prediction_df,\n",
    "    historical_list,\n",
    "    empty_list=[None]*(len(historical_list)-1),\n",
    "    last_value=[historical_list[-1]],\n",
    "    connect_length=5,\n",
    "    line_width=5\n",
    ")\n",
    "\n",
    "display(prediction_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleanup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for d in sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name)[\n",
    "    \"ModelPackageSummaryList\"\n",
    "]:\n",
    "    print(d[\"ModelPackageArn\"])\n",
    "    sm_client.delete_model_package(ModelPackageName=d[\"ModelPackageArn\"])\n",
    "\n",
    "sm_client.delete_model_package_group(ModelPackageGroupName=model_package_group_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean up Amazon SageMaker experiment resources with the [SageMaker Python SDK](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-cleanup.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d01552-0523-41f5-a40d-a2f29b510fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.experiments.experiment import _Experiment\n",
    "\n",
    "exp = _Experiment.load(experiment_name=experiment_name, sagemaker_session=sagemaker_session)\n",
    "exp._delete_all(action=\"--force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2892a-8fdc-42a4-ac99-415907cd739c",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32096a1-b3e9-4843-9baf-9afbc5d998c2",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
